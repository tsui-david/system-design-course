{"problem_youtube_3": {"questions": [{"question": "What API endpoints should the server have?", "answer": "We should have at the minimum: 1. Uploading/Streaming videos 2. Endpoints for video metadata such as likes/dislikes, comments", "hints": ["Think back to the core features of YouTube. What are some of the features YouTube should have?"]}, {"answer": "The client uploader can upload videos in chunks to help with threading as well as bandwidth and video indexing. This is known as _multi part_ upload. S3 actually [has such feature built in](https://docs.aws.amazon.com/AmazonS3/latest/dev/UsingRESTAPImpUpload.html). It works by having the client initiate a request and the api responds with an upload id. The client then begins to chunk the content and send the chunk data, the hash of the data so that the server can validate the integrity of the chunk, and the chunk sequence number.", "question": "How do we upload the video file itself?", "hints": ["One strategy is to directly upload the entire file to some sort of storage like Amazon S3. However some videos can be long and as a result the uploaded file can be pretty large. How should this be handled?"]}, {"answer": "The response should include a json body of its metadata such as its current like, dislike, details, author, tags, category, comments There could be a separated out request for the binary video itself as that could be in chunks. These would essentially be done through another type of video protocol.", "question": "How should the GET request response look like?", "hints": []}, {"answer": "We can reuse our endpoint: `https://youtube.com/<user_id>/videos/<video_id>` and do a POST with like disklike metadata to the endpoint.", "question": "Finally, how should we handle the comment/like/dislike?", "hints": ["Thank back to how the video was uploaded. Similarly, we face the same problem of large file download."]}]}, "lesson_id": "youtube3", "lesson_title": "Design YouTube High Level API", "video_url": "https://youtu.be/rykxT92rKEg"}